{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tools/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "base_path = '/home/datasets/rsna-intracranial-hemorrhage-detection/'\n",
    "csv_path = base_path + 'stage_2_train.csv'\n",
    "items = base_path + 'stage_2_train/'\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch, csv, pydicom\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "class RSNASet(Dataset):\n",
    "    def __init__(self, csv_path, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        labels = {}\n",
    "        with open(csv_path) as f:\n",
    "            rdr = csv.reader(f)\n",
    "            next(rdr)\n",
    "            for rows in rdr:\n",
    "                fn = '_'.join(rows[0].split('_')[0:2])\n",
    "                try:\n",
    "                    labels[fn].append(int(rows[1]))\n",
    "                except:\n",
    "                    labels[fn] = [int(rows[1])]\n",
    "        for fn in labels.keys():\n",
    "            # \"any\" should really be the classification \"none\"\n",
    "            # so, it should only be 1 if nothing else is true - swap the values\n",
    "            labels[fn][5] = abs(labels[fn][5]-1)\n",
    "        self.labels = labels\n",
    "        self.files = list(labels.keys())\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        file = self.files[idx]\n",
    "        label = torch.argmax(torch.FloatTensor(self.labels[file]))\n",
    "        img = pydicom.dcmread(self.root_dir+file+'.dcm').pixel_array\n",
    "        tf = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
    "            transforms.ConvertImageDtype(torch.float),\n",
    "        ])\n",
    "        img = tf(Image.fromarray(img))\n",
    "        return img, label\n",
    "tempset = RSNASet(csv_path=csv_path, root_dir=items)\n",
    "BATCH_SIZE = 128\n",
    "import math\n",
    "trainlen = math.floor(0.80 * len(tempset)) # 80/20 train/val split\n",
    "vallen = len(tempset) - trainlen\n",
    "_, valset = torch.utils.data.random_split(tempset, [trainlen, vallen], generator=torch.Generator().manual_seed(42))\n",
    "model = 'resnet18'\n",
    "valloader = torch.utils.data.DataLoader(valset,batch_size=BATCH_SIZE,shuffle=True,num_workers=4)\n",
    "classes = ('epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural','none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch, csv, pydicom\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "class RSNATestSet(Dataset):\n",
    "    def __init__(self, files, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.files = files\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        file = self.files[idx]\n",
    "        img = pydicom.dcmread(file).pixel_array\n",
    "        tf = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.Lambda(lambda x: x.repeat(3,1,1)),\n",
    "            transforms.ConvertImageDtype(torch.float),\n",
    "        ])\n",
    "        img = tf(Image.fromarray(img))\n",
    "        return idx, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/dsingh/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available - using CUDA!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 1177/1177 [22:07<00:00,  1.13s/batch, accuracy=89.2, loss=0.638]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "BATCH_SIZE = 128\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "base_path = '/home/datasets/rsna-intracranial-hemorrhage-detection/'\n",
    "items = base_path + 'stage_2_test/'\n",
    "dcms = glob.glob('{}*.dcm'.format(items))\n",
    "testset = RSNATestSet(files=dcms, root_dir=items)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=BATCH_SIZE,shuffle=True,num_workers=4)\n",
    "classes = ('epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'none')\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False, num_classes=len(classes))\n",
    "if not torch.cuda.is_available():\n",
    "    model.load_state_dict(torch.load('weights/split_resnet18/epoch25.pth', map_location=torch.device('cpu')))\n",
    "else:\n",
    "    model.load_state_dict(torch.load('weights/split_resnet18/epoch25.pth'))\n",
    "model.eval()\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available - using CUDA!\")\n",
    "    model = model.cuda()\n",
    "running_loss = 0.0\n",
    "batch = 0\n",
    "total_correct = 0\n",
    "total = 0\n",
    "with tqdm(valloader, unit=\"batch\") as tepoch:\n",
    "        model.eval()\n",
    "        for inputs, labels in tepoch:\n",
    "            tepoch.set_description(f\"Validating\")\n",
    "            if torch.cuda.is_available():\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            outputs = F.softmax(outputs, dim=1)\n",
    "            predictions = outputs.argmax(dim=1, keepdim=True).squeeze()\n",
    "            correct = (predictions == labels).sum().item()\n",
    "            total_correct += correct\n",
    "            total += BATCH_SIZE\n",
    "            accuracy = total_correct / total # batch_size\n",
    "            running_loss += loss.item()\n",
    "            if batch > 0:\n",
    "                tepoch.set_postfix(loss=running_loss/batch, accuracy=100. * accuracy)\n",
    "            batch += 1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bb0305c1ea15e60bc0dcdadbaa5b2331a4128e32bab6d9cd52b9abc34b23ae22"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
