{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# import zipfile\n",
    "\n",
    "# url = \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\"\n",
    "\n",
    "file_name = \"horse-or-human.zip\"\n",
    "training_dir = \"horse-or-human/training\"\n",
    "# urllib.request.urlretrieve(url, file_name)\n",
    "# zip_ref = zipfile.ZipFile(file_name, 'r')\n",
    "# zip_ref.extractall(training_dir)\n",
    "# zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "train_generator = train_datagen.flow_from_directory(training_dir, target_size=(300,300), class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-03 10:11:46.173429: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-03 10:11:46.185248: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2397400000 Hz\n",
      "2022-05-03 10:11:46.186726: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c86a888030 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-05-03 10:11:46.186755: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Dense, BatchNormalization, Activation, MaxPool2D, GlobalAveragePooling2D, Add, Dropout\n",
    "from tensorflow.keras import Model\n",
    "## resnet paper - https://arxiv.org/pdf/1512.03385.pdf\n",
    "## issue may be images are too small to run convolutions,\n",
    "## but residual blocks should provide some accuracy bumps\n",
    "\n",
    "class ResidualBlock(Model):\n",
    "    def __init__(self, channel_in = 64, channel_out = 256):\n",
    "        super().__init__()\n",
    "        \n",
    "        channel = channel_out // 4\n",
    "        self.dropout = Dropout(.2)\n",
    "        self.conv1 = Conv2D(channel, kernel_size = (1, 1), padding = \"same\")\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.av1 = Activation(tf.nn.relu)\n",
    "        self.conv2 = Conv2D(channel, kernel_size = (3, 3), padding = \"same\")\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.av2 = Activation(tf.nn.relu)\n",
    "        self.conv3 = Conv2D(channel_out, kernel_size = (1, 1), padding = \"same\")\n",
    "        self.bn3 = BatchNormalization()\n",
    "        self.shortcut = self._shortcut(channel_in, channel_out)\n",
    "        self.add = Add()\n",
    "        self.av3 = Activation(tf.nn.relu)\n",
    "        \n",
    "    def call(self, x):\n",
    "        h = self.conv1(x)\n",
    "        h = self.bn1(h)\n",
    "        h = self.av1(h)\n",
    "        h = self.conv2(h)\n",
    "        h = self.bn2(h)\n",
    "        h = self.av2(h)\n",
    "        h = self.conv3(h)\n",
    "        h = self.bn3(h)\n",
    "        shortcut = self.shortcut(x)\n",
    "        h = self.add([h, shortcut])\n",
    "        y = self.av3(h)\n",
    "        return y\n",
    "    \n",
    "    def _shortcut(self, channel_in, channel_out):\n",
    "        if channel_in == channel_out:\n",
    "            return lambda x : x\n",
    "        else:\n",
    "            return self._projection(channel_out)\n",
    "        \n",
    "    def _projection(self, channel_out):\n",
    "        return Conv2D(channel_out, kernel_size = (1, 1), padding = \"same\")\n",
    "           \n",
    "class LightNet18(Model):\n",
    "    def __init__(self, input_shape, output_dim):\n",
    "        super().__init__()                \n",
    "        self._layers = [\n",
    "            # conv1\n",
    "            Conv2D(64, input_shape = input_shape, kernel_size = (7, 7), strides=(2, 2), padding = \"same\"),\n",
    "            BatchNormalization(),\n",
    "            Activation(tf.nn.relu),\n",
    "            # conv2_x\n",
    "            MaxPool2D(pool_size = (3, 3), strides = (2, 2), padding = \"same\"),\n",
    "            ResidualBlock(64, 64),\n",
    "            # conv3_x\n",
    "            Conv2D(128, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            ResidualBlock(128, 128),\n",
    "            # conv4_x\n",
    "            Conv2D(256, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            ResidualBlock(256, 256),\n",
    "            # conv5_x\n",
    "            Conv2D(512, kernel_size = (1, 1), strides=(2, 2)),\n",
    "            ResidualBlock(512, 512),\n",
    "            # last part\n",
    "            GlobalAveragePooling2D(),\n",
    "            Dense(1000, activation = tf.nn.relu),\n",
    "            Dense(output_dim, activation = tf.nn.softmax)\n",
    "        ]\n",
    "        \n",
    "    def call(self, x):\n",
    "        for layer in self._layers:\n",
    "            if isinstance(layer, list):\n",
    "                for l in layer:\n",
    "                    x = l(x)    \n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "       \n",
    "    \n",
    "model = LightNet18((300, 300, 3), 2)\n",
    "model.build(input_shape = (None, 300, 300, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_generator, epochs\u001b[39m=\u001b[39;49m\u001b[39m15\u001b[39;49m)\n",
      "File \u001b[0;32m/home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=105'>106</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_method_wrapper\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=106'>107</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_in_multi_worker_mode():  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=107'>108</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=109'>110</a>\u001b[0m   \u001b[39m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=110'>111</a>\u001b[0m   \u001b[39mif\u001b[39;00m dc_context\u001b[39m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[0;32m/home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1049\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1042'>1043</a>\u001b[0m   val_x, val_y, val_sample_weight \u001b[39m=\u001b[39m (\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1043'>1044</a>\u001b[0m       data_adapter\u001b[39m.\u001b[39munpack_x_y_sample_weight(validation_data))\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1045'>1046</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribute_strategy\u001b[39m.\u001b[39mscope(), \\\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1046'>1047</a>\u001b[0m      training_utils\u001b[39m.\u001b[39mRespectCompiledTrainableState(\u001b[39mself\u001b[39m):\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1047'>1048</a>\u001b[0m   \u001b[39m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1048'>1049</a>\u001b[0m   data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mDataHandler(\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1049'>1050</a>\u001b[0m       x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1050'>1051</a>\u001b[0m       y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1051'>1052</a>\u001b[0m       sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1052'>1053</a>\u001b[0m       batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1053'>1054</a>\u001b[0m       steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1054'>1055</a>\u001b[0m       initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1055'>1056</a>\u001b[0m       epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1056'>1057</a>\u001b[0m       shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1057'>1058</a>\u001b[0m       class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1058'>1059</a>\u001b[0m       max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1059'>1060</a>\u001b[0m       workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1060'>1061</a>\u001b[0m       use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1061'>1062</a>\u001b[0m       model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1062'>1063</a>\u001b[0m       steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution)\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1064'>1065</a>\u001b[0m   \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py?line=1065'>1066</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
      "File \u001b[0;32m/home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py:1105\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1101'>1102</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution_value \u001b[39m=\u001b[39m steps_per_execution\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1103'>1104</a>\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1104'>1105</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1105'>1106</a>\u001b[0m     x,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1106'>1107</a>\u001b[0m     y,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1107'>1108</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1108'>1109</a>\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1109'>1110</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1110'>1111</a>\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1111'>1112</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1112'>1113</a>\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1113'>1114</a>\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1114'>1115</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1115'>1116</a>\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mds_context\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1116'>1117</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel)\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1118'>1119</a>\u001b[0m strategy \u001b[39m=\u001b[39m ds_context\u001b[39m.\u001b[39mget_strategy()\n\u001b[1;32m   <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=1119'>1120</a>\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter\u001b[39m.\u001b[39mget_dataset()\n",
      "File \u001b[0;32m/home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py:909\u001b[0m, in \u001b[0;36mKerasSequenceAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=906'>907</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_keras_sequence \u001b[39m=\u001b[39m x\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=907'>908</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_enqueuer \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=908'>909</a>\u001b[0m \u001b[39msuper\u001b[39;49m(KerasSequenceAdapter, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=909'>910</a>\u001b[0m     x,\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=910'>911</a>\u001b[0m     shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,  \u001b[39m# Shuffle is handed in the _make_callable override.\u001b[39;49;00m\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=911'>912</a>\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=912'>913</a>\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=913'>914</a>\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=914'>915</a>\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=915'>916</a>\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py:786\u001b[0m, in \u001b[0;36mGeneratorDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=781'>782</a>\u001b[0m \u001b[39msuper\u001b[39m(GeneratorDataAdapter, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(x, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=783'>784</a>\u001b[0m \u001b[39m# Since we have to know the dtype of the python generator when we build the\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=784'>785</a>\u001b[0m \u001b[39m# dataset, we have to look at a batch to infer the structure.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=785'>786</a>\u001b[0m peek, x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_peek_and_restore(x)\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=786'>787</a>\u001b[0m peek \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_standardize_batch(peek)\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=787'>788</a>\u001b[0m peek \u001b[39m=\u001b[39m _process_tensorlike(peek)\n",
      "File \u001b[0;32m/home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py:920\u001b[0m, in \u001b[0;36mKerasSequenceAdapter._peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=917'>918</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=918'>919</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_peek_and_restore\u001b[39m(x):\n\u001b[0;32m--> <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py?line=919'>920</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m x[\u001b[39m0\u001b[39;49m], x\n",
      "File \u001b[0;32m/home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py:65\u001b[0m, in \u001b[0;36mIterator.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py?line=61'>62</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_index_array()\n\u001b[1;32m     <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py?line=62'>63</a>\u001b[0m index_array \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_array[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m*\u001b[39m idx:\n\u001b[1;32m     <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py?line=63'>64</a>\u001b[0m                                \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m*\u001b[39m (idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)]\n\u001b[0;32m---> <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py?line=64'>65</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_batches_of_transformed_samples(index_array)\n",
      "File \u001b[0;32m/home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py:227\u001b[0m, in \u001b[0;36mBatchFromFilesMixin._get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py?line=224'>225</a>\u001b[0m filepaths \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepaths\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py?line=225'>226</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(index_array):\n\u001b[0;32m--> <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py?line=226'>227</a>\u001b[0m     img \u001b[39m=\u001b[39m load_img(filepaths[j],\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py?line=227'>228</a>\u001b[0m                    color_mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolor_mode,\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py?line=228'>229</a>\u001b[0m                    target_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_size,\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py?line=229'>230</a>\u001b[0m                    interpolation\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minterpolation)\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py?line=230'>231</a>\u001b[0m     x \u001b[39m=\u001b[39m img_to_array(img, data_format\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_format)\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py?line=231'>232</a>\u001b[0m     \u001b[39m# Pillow images should be closed after `load_img`,\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/iterator.py?line=232'>233</a>\u001b[0m     \u001b[39m# but not PIL images.\u001b[39;00m\n",
      "File \u001b[0;32m/home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/utils.py:111\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/utils.py?line=108'>109</a>\u001b[0m     color_mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgrayscale\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/utils.py?line=109'>110</a>\u001b[0m \u001b[39mif\u001b[39;00m pil_image \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/utils.py?line=110'>111</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCould not import PIL.Image. \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/utils.py?line=111'>112</a>\u001b[0m                       \u001b[39m'\u001b[39m\u001b[39mThe use of `load_img` requires PIL.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/utils.py?line=112'>113</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    <a href='file:///home/tools/anaconda3/envs/tensorflow/lib/python3.8/site-packages/keras_preprocessing/image/utils.py?line=113'>114</a>\u001b[0m     img \u001b[39m=\u001b[39m pil_image\u001b[39m.\u001b[39mopen(io\u001b[39m.\u001b[39mBytesIO(f\u001b[39m.\u001b[39mread()))\n",
      "\u001b[0;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "history = model.fit(train_generator, epochs=15)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "db633a2415b8a28dc946d9e13a3dbc9dc65443e0a408813de63e49810352fa2a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
